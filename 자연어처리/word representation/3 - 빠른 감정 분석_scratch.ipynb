{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ben Trevett 의 [Faster Sentiment Analysis](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb) 튜토리얼을 한글 데이터셋에 적용해보는 연습이다. 데이터셋은 [네이버 영화 평점 데이터](https://github.com/e9t/nsmc)을 이용한다.\n",
    "\n",
    "이 튜토리얼에서는 `FastText` 모델을 이용해서 모델을 경량화해보자. 그리고 이 모델에서는 사전학습된 벡터를 이용하지 않고 훈련시켜 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "\n",
    "`FastText` 논문의 핵심 아이디어 중 하나는 입력 문장의 마지막에 문장 구성 토큰들의 n-gram을 추가로 도입하는 것이다. 우리는 여기서 bi-gram을 도입하자. 예를 들어 \"how are you ?\"의 bi-gram은 \"how are\", \"are you\" and \"you ?\"이다.\n",
    "\n",
    "따라서 여기서 `generate_bigrams` 함수를 도입하여 토큰화된 문장의 뒤에 bi-gram을 추가하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('너', '임마'), ('먹고', '다니냐'), ('밥은', '먹고'), ('임마', '밥은')}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['너', '임마', '밥은', '먹고', '다니냐']\n",
    "n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['너', '임마', '밥은', '먹고', '다니냐', '밥은 먹고', '너 임마', '임마 밥은', '먹고 다니냐']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_bigrams(['너', '임마', '밥은', '먹고', '다니냐'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchtext의 `Field`는 `preprocessing` 과정이 있어서 여기에 함수를 전달하면 토크나이징 후 적용된다. 여기에 `generate_bigrams` 함수를 넣자.\n",
    "\n",
    "우리는 한글 데이터를 다루므로 토크나이저 또한 별도로 지정해야한다. 여기서는 [KoNLPy](https://konlpy-ko.readthedocs.io/ko/v0.4.3/)의 은전한닢 tokenizer를 이용한다. 또한 패딩을 추가한다. 여기서는 RNN 안쓸 거기 때문에 packed padded seq.를 쓸 수 없어서 `include_lengths=True` 또한 넣을 필요가 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "TEXT = data.Field(tokenize = mecab.morphs, preprocessing = generate_bigrams)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리된 네이버 영화 평점 데이터를 불러오고 검증 데이터를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ('text', <torchtext.data.field.Field at 0x7f4d84f980d0>),\n",
       " 'label': ('label', <torchtext.data.field.LabelField at 0x7f4d84f94e50>)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = {'text': ('text',TEXT), 'label': ('label',LABEL)}\n",
    "# dictionary 형식은 {csv컬럼명 : (데이터 컬럼명, Field이름)}\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.TabularDataset.splits(\n",
    "                            path = 'data',\n",
    "                            train = 'train_data.csv',\n",
    "                            test = 'test_data.csv',\n",
    "                            format = 'csv',\n",
    "                            fields = fields,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['야한',\n",
       "  '장면',\n",
       "  '기다리',\n",
       "  '는',\n",
       "  '것',\n",
       "  '도',\n",
       "  '곤욕',\n",
       "  '이',\n",
       "  '군',\n",
       "  '야한 장면',\n",
       "  '장면 기다리',\n",
       "  '는 것',\n",
       "  '이 군',\n",
       "  '것 도',\n",
       "  '기다리 는',\n",
       "  '곤욕 이',\n",
       "  '도 곤욕'],\n",
       " 'label': '0'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어는 그냥 전처리 없이 해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data,\n",
    "                max_size = MAX_VOCAB_SIZE,\n",
    "                #vectors = 'fasttext.simple.300d',\n",
    "                #unk_init = torch.Tensor.normal_\n",
    "                )\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '.',\n",
       " '이',\n",
       " '는',\n",
       " '영화',\n",
       " '다',\n",
       " '고',\n",
       " '하',\n",
       " '도',\n",
       " '의',\n",
       " '가',\n",
       " '은',\n",
       " '에',\n",
       " '을',\n",
       " '보',\n",
       " '한',\n",
       " '..',\n",
       " '게',\n",
       " ',',\n",
       " '다 .',\n",
       " '. .',\n",
       " '들',\n",
       " '!',\n",
       " '지',\n",
       " '. ..',\n",
       " '를',\n",
       " '있',\n",
       " '없',\n",
       " '?',\n",
       " '좋',\n",
       " '나',\n",
       " '었',\n",
       " '만',\n",
       " '는데',\n",
       " '너무',\n",
       " '봤',\n",
       " '적',\n",
       " '안',\n",
       " '정말',\n",
       " '로',\n",
       " '음',\n",
       " '으로',\n",
       " '것',\n",
       " '아',\n",
       " '네요',\n",
       " '재밌',\n",
       " '어',\n",
       " '점',\n",
       " '하 고',\n",
       " '같',\n",
       " '진짜',\n",
       " '지만',\n",
       " '했',\n",
       " '에서',\n",
       " '기',\n",
       " '않',\n",
       " '네',\n",
       " '았',\n",
       " '거',\n",
       " '는 영화',\n",
       " '수',\n",
       " '되',\n",
       " 'ㅋㅋ',\n",
       " '영화 .',\n",
       " '면',\n",
       " '하 는',\n",
       " '과',\n",
       " '말',\n",
       " '인',\n",
       " '연기',\n",
       " '최고',\n",
       " '잘',\n",
       " '주',\n",
       " '~',\n",
       " '내',\n",
       " '평점',\n",
       " '어요',\n",
       " '보 고',\n",
       " '던',\n",
       " '이런',\n",
       " '와',\n",
       " 'ㅋㅋㅋ',\n",
       " '1',\n",
       " '할',\n",
       " '해',\n",
       " '스토리',\n",
       " '왜',\n",
       " '습니다',\n",
       " '겠',\n",
       " '...',\n",
       " '이 다',\n",
       " '드라마',\n",
       " '생각',\n",
       " '아니',\n",
       " '지 않',\n",
       " '그',\n",
       " '싶',\n",
       " '더',\n",
       " '듯',\n",
       " '사람',\n",
       " '이 영화',\n",
       " '감동',\n",
       " '때',\n",
       " '함',\n",
       " '. ...',\n",
       " '배우',\n",
       " '까지',\n",
       " '본',\n",
       " '좀',\n",
       " '뭐',\n",
       " '하 다',\n",
       " '알',\n",
       " '만들',\n",
       " '볼',\n",
       " '들 이',\n",
       " '내용',\n",
       " '감독',\n",
       " '고 싶',\n",
       " '라',\n",
       " '보다',\n",
       " '재미',\n",
       " '지루',\n",
       " '그냥',\n",
       " '재미있',\n",
       " '중',\n",
       " '보 는',\n",
       " '시간',\n",
       " '하 게',\n",
       " '없 는',\n",
       " '있 는',\n",
       " '년',\n",
       " '10',\n",
       " '잼',\n",
       " '재미없',\n",
       " '영화 를',\n",
       " '였',\n",
       " '쓰레기',\n",
       " '사랑',\n",
       " '못',\n",
       " '냐',\n",
       " '수 있',\n",
       " '! !',\n",
       " '영화 는',\n",
       " '네요 .',\n",
       " '한 영화',\n",
       " '은 영화',\n",
       " '서',\n",
       " '영화 가',\n",
       " '2',\n",
       " '야',\n",
       " '라고',\n",
       " '니',\n",
       " '었 다',\n",
       " '봤 는데',\n",
       " '음 .',\n",
       " '다시',\n",
       " '면서',\n",
       " '번',\n",
       " '적 인',\n",
       " '나오',\n",
       " '작품',\n",
       " '하나',\n",
       " '이거',\n",
       " '없 다',\n",
       " '줄',\n",
       " '해서',\n",
       " '습니다 .',\n",
       " '남',\n",
       " '마지막',\n",
       " '개',\n",
       " '정도',\n",
       " '같 은',\n",
       " '이건',\n",
       " '임',\n",
       " 'ㅋ',\n",
       " '액션',\n",
       " '끝',\n",
       " '3',\n",
       " '입니다',\n",
       " '완전',\n",
       " '하 지',\n",
       " '좋 은',\n",
       " '건',\n",
       " '라는',\n",
       " '최고 의',\n",
       " '많',\n",
       " '다는',\n",
       " '의 영화',\n",
       " '기대',\n",
       " '내 가',\n",
       " '장면',\n",
       " '좋 았',\n",
       " '아깝',\n",
       " '분',\n",
       " '처음',\n",
       " '것 같',\n",
       " '참',\n",
       " '도 없',\n",
       " '대',\n",
       " '네 .',\n",
       " '들 의',\n",
       " '으면',\n",
       " '다가',\n",
       " '고 .',\n",
       " '이렇게',\n",
       " '적 이',\n",
       " '이게',\n",
       " '지금',\n",
       " \"'\",\n",
       " '모르',\n",
       " '일',\n",
       " '편',\n",
       " '최악',\n",
       " '성',\n",
       " '돈',\n",
       " '이야기',\n",
       " '별로',\n",
       " '는 것',\n",
       " '배우 들',\n",
       " '느낌',\n",
       " '되 는',\n",
       " '시',\n",
       " '님',\n",
       " '1 점',\n",
       " '된',\n",
       " '는 거',\n",
       " '봐도',\n",
       " '어서',\n",
       " '자',\n",
       " '전',\n",
       " '넘',\n",
       " '다고',\n",
       " '애',\n",
       " '고 있',\n",
       " '인데',\n",
       " '걸',\n",
       " '10 점',\n",
       " 'ㅠㅠ',\n",
       " '그리고',\n",
       " '좋 아',\n",
       " '이해',\n",
       " '난',\n",
       " '한국',\n",
       " '명작',\n",
       " '또',\n",
       " '^^',\n",
       " '게 봤',\n",
       " '역시',\n",
       " '여자',\n",
       " '에게',\n",
       " '는지',\n",
       " '많이',\n",
       " '주 는',\n",
       " '는데 .',\n",
       " '부터',\n",
       " '이상',\n",
       " '주인공',\n",
       " '재밌 게',\n",
       " '만든',\n",
       " '들 은',\n",
       " '았 다',\n",
       " '보 면',\n",
       " '합니다',\n",
       " '지루 하',\n",
       " '!!',\n",
       " '받',\n",
       " '평점 이',\n",
       " '는 게',\n",
       " '두',\n",
       " '우리',\n",
       " '괜찮',\n",
       " '가 없',\n",
       " '살',\n",
       " '적 으로',\n",
       " '엔',\n",
       " '기억',\n",
       " '이 없',\n",
       " '길',\n",
       " '고 ,',\n",
       " '수 없',\n",
       " '없 고',\n",
       " '연출',\n",
       " '이나',\n",
       " 'ㅎㅎ',\n",
       " '재',\n",
       " '! !!',\n",
       " '저',\n",
       " '때문',\n",
       " '할 수',\n",
       " '한다',\n",
       " '말 이',\n",
       " '겠 다',\n",
       " '이 너무',\n",
       " '이런 영화',\n",
       " '있 었',\n",
       " '요',\n",
       " '사람 들',\n",
       " '꼭',\n",
       " '보 기',\n",
       " '다 !',\n",
       " '아깝 다',\n",
       " '랑',\n",
       " '했 다',\n",
       " '며',\n",
       " '죽',\n",
       " '긴',\n",
       " '현실',\n",
       " '결말',\n",
       " '무슨',\n",
       " '이 있',\n",
       " 'ㅡㅡ',\n",
       " '내내',\n",
       " '어요 .',\n",
       " '마음',\n",
       " '남자',\n",
       " '영화 다',\n",
       " '거 같',\n",
       " '이 었',\n",
       " '굿',\n",
       " '세요',\n",
       " '소재',\n",
       " '짱',\n",
       " '속',\n",
       " '공포',\n",
       " '아서',\n",
       " '은데',\n",
       " '다른',\n",
       " '안 되',\n",
       " '전개',\n",
       " '볼 만',\n",
       " '인생',\n",
       " '같 다',\n",
       " '뿐',\n",
       " '를 보',\n",
       " '씨',\n",
       " '도 안',\n",
       " '~~',\n",
       " '때문 에',\n",
       " '별',\n",
       " '지 .',\n",
       " '필요',\n",
       " '유치',\n",
       " '아요',\n",
       " '입니다 .',\n",
       " '오',\n",
       " '짜증',\n",
       " '아이',\n",
       " '감동 적',\n",
       " '이 고',\n",
       " ';;',\n",
       " '음악',\n",
       " '가장',\n",
       " '영화 중',\n",
       " '있 다',\n",
       " ')',\n",
       " '수준',\n",
       " '것 이',\n",
       " 'ㄷ',\n",
       " '밋',\n",
       " '반전',\n",
       " '낮',\n",
       " '일본',\n",
       " '웃',\n",
       " '매력',\n",
       " 'ㅠ',\n",
       " '다니',\n",
       " '맞',\n",
       " '가슴',\n",
       " '없이',\n",
       " '하 기',\n",
       " '인지',\n",
       " '높',\n",
       " '듯 .',\n",
       " '는 내내',\n",
       " '인간',\n",
       " '하 지만',\n",
       " '던 영화',\n",
       " '영화 의',\n",
       " '급',\n",
       " '보 지',\n",
       " '데',\n",
       " '원작',\n",
       " '(',\n",
       " '? ?',\n",
       " '주 고',\n",
       " '가 있',\n",
       " '만드',\n",
       " '재 밋',\n",
       " '영화 !',\n",
       " '냐 ?',\n",
       " '눈물',\n",
       " '하 면',\n",
       " '나 는',\n",
       " '본 영화',\n",
       " '는 사람',\n",
       " '준',\n",
       " '노',\n",
       " '인가',\n",
       " '을까',\n",
       " '마',\n",
       " '보여',\n",
       " '지 는',\n",
       " '싶 다',\n",
       " '신',\n",
       " 'ㅋㅋ ㅋㅋ',\n",
       " '용',\n",
       " '자체',\n",
       " '봤 다',\n",
       " '찍',\n",
       " '울',\n",
       " '4',\n",
       " '모든',\n",
       " '여',\n",
       " '코미디',\n",
       " '5',\n",
       " '영화 였',\n",
       " '화',\n",
       " ', ,',\n",
       " '한 번',\n",
       " '아직',\n",
       " '않 고',\n",
       " '영화 에',\n",
       " '눈',\n",
       " '모르 겠',\n",
       " '나오 는',\n",
       " '아닌',\n",
       " '대박',\n",
       " '추천',\n",
       " '쓰',\n",
       " '을 때',\n",
       " '처럼',\n",
       " '했 는데',\n",
       " '몰입',\n",
       " '는다',\n",
       " '재밌 었',\n",
       " '많 은',\n",
       " '스럽',\n",
       " '대한',\n",
       " '지 도',\n",
       " '끝 까지',\n",
       " '만들 어',\n",
       " '캐릭터',\n",
       " '솔직히',\n",
       " '-',\n",
       " '의 연기',\n",
       " '란',\n",
       " '영화 보',\n",
       " '줄 알',\n",
       " '만들 었',\n",
       " '고 보',\n",
       " '그런',\n",
       " '여운',\n",
       " '죠',\n",
       " '아 하',\n",
       " '몇',\n",
       " '도 있',\n",
       " '실망',\n",
       " 'ㅎ',\n",
       " '아주',\n",
       " '에 는',\n",
       " '도 않',\n",
       " '건지',\n",
       " '모두',\n",
       " '전혀',\n",
       " '알 았',\n",
       " '가족',\n",
       " '뭔가',\n",
       " '나라',\n",
       " '함 .',\n",
       " '후',\n",
       " '연기력',\n",
       " '작',\n",
       " '너무 좋',\n",
       " '시리즈',\n",
       " '였 다',\n",
       " '잼 있',\n",
       " '좋 다',\n",
       " '에 대한',\n",
       " '그래도',\n",
       " '다면',\n",
       " '될',\n",
       " '만 하',\n",
       " '볼 수',\n",
       " '\"\"',\n",
       " '생각 하',\n",
       " '. 영화',\n",
       " '것 도',\n",
       " '근데',\n",
       " '들 을',\n",
       " '었 던',\n",
       " '공감',\n",
       " '먹',\n",
       " '쓰레기 영화',\n",
       " '지 말',\n",
       " '했 던',\n",
       " '없 었',\n",
       " '치',\n",
       " '작가',\n",
       " '표현',\n",
       " '내용 이',\n",
       " ';',\n",
       " '보 다가',\n",
       " '합니다 .',\n",
       " '고 봤',\n",
       " '지 ?',\n",
       " '진',\n",
       " '하 네요',\n",
       " '도 좋',\n",
       " '바',\n",
       " '7',\n",
       " '는 듯',\n",
       " '싶 은',\n",
       " '제',\n",
       " '제목',\n",
       " '개봉',\n",
       " '대단',\n",
       " '없 음',\n",
       " '었 음',\n",
       " '게 하',\n",
       " '그렇',\n",
       " '모습',\n",
       " '재밌 다',\n",
       " '해 주',\n",
       " '계속',\n",
       " '이랑',\n",
       " '게 되',\n",
       " '0',\n",
       " '었 는데',\n",
       " '아쉽',\n",
       " '극장',\n",
       " '비',\n",
       " '어디',\n",
       " '대사',\n",
       " '재미있 게',\n",
       " '않 은',\n",
       " 'OO',\n",
       " '부분',\n",
       " '이걸',\n",
       " '한다 .',\n",
       " '봤 습니다',\n",
       " '이 라는',\n",
       " '이 안',\n",
       " '연기 가',\n",
       " '지 마',\n",
       " '애 들',\n",
       " '웃기',\n",
       " '아 .',\n",
       " '다시 보',\n",
       " '가 너무',\n",
       " '막장',\n",
       " '중 에',\n",
       " '최악 의',\n",
       " '기분',\n",
       " '놓',\n",
       " '보이',\n",
       " '해도',\n",
       " '보 면서',\n",
       " '이 라',\n",
       " '만 한',\n",
       " '봐야',\n",
       " '을 보',\n",
       " '중간',\n",
       " '친구',\n",
       " '않 는',\n",
       " '을 수',\n",
       " '구',\n",
       " '감독 이',\n",
       " '\"',\n",
       " '....',\n",
       " '진심',\n",
       " '된다',\n",
       " '들 도',\n",
       " '아까운',\n",
       " '아니 다',\n",
       " '연기 도',\n",
       " '물',\n",
       " '억지',\n",
       " '타임',\n",
       " '는 .',\n",
       " '보 게',\n",
       " '씬',\n",
       " '요즘',\n",
       " '가지',\n",
       " '시간 이',\n",
       " '재미없 다',\n",
       " '노래',\n",
       " '이제',\n",
       " '믿',\n",
       " '점 도',\n",
       " '않 았',\n",
       " '이 필요',\n",
       " '딱',\n",
       " '삶',\n",
       " '싫',\n",
       " '구나',\n",
       " '가 는',\n",
       " '라도',\n",
       " '보여 주',\n",
       " '도 아깝',\n",
       " '만드 는',\n",
       " '영상',\n",
       " '잔잔',\n",
       " '스릴러',\n",
       " '었 어요',\n",
       " '찾',\n",
       " '나 ?',\n",
       " '조금',\n",
       " '나왔',\n",
       " '내용 도',\n",
       " '이유',\n",
       " '. 정말',\n",
       " '점수',\n",
       " '기 도',\n",
       " '긴장감',\n",
       " '에 도',\n",
       " '재미 도',\n",
       " '. 이',\n",
       " '는 건',\n",
       " '영화 입니다',\n",
       " '인 영화',\n",
       " '제대로',\n",
       " '영화 라고',\n",
       " '하 면서',\n",
       " '남 는',\n",
       " '잇',\n",
       " '8',\n",
       " '아니 라',\n",
       " '라면',\n",
       " '아름다운',\n",
       " '있 고',\n",
       " '개인',\n",
       " '/',\n",
       " '점 이',\n",
       " '같이',\n",
       " '만큼',\n",
       " '부족',\n",
       " '았 는데',\n",
       " '지만 ,',\n",
       " '날',\n",
       " '시대',\n",
       " '잘 봤',\n",
       " '차라리',\n",
       " '사',\n",
       " '사람 이',\n",
       " '수 가',\n",
       " '하지만',\n",
       " '제일',\n",
       " '영화 로',\n",
       " '시작',\n",
       " 'ㅜㅜ',\n",
       " '이 지',\n",
       " '무섭',\n",
       " '아니 고',\n",
       " '이것',\n",
       " '한테',\n",
       " '스토리 가',\n",
       " '지만 .',\n",
       " '고 나',\n",
       " '나름',\n",
       " '당시',\n",
       " '특히',\n",
       " '던데',\n",
       " '엔딩',\n",
       " '세',\n",
       " '오랜만',\n",
       " '세상',\n",
       " '어떻게',\n",
       " '재밌 어요',\n",
       " '해요',\n",
       " '려고',\n",
       " '보 니',\n",
       " '한국 영화',\n",
       " '분 들',\n",
       " '봐',\n",
       " '팬',\n",
       " '니까',\n",
       " '절대',\n",
       " '도 아니',\n",
       " '명',\n",
       " '감',\n",
       " '스토리 도',\n",
       " '의미',\n",
       " '. ....',\n",
       " '강추',\n",
       " '공포 영화',\n",
       " '봄',\n",
       " '욕',\n",
       " '9',\n",
       " '훌륭',\n",
       " '못하',\n",
       " '이 라고',\n",
       " '임 .',\n",
       " '는 줄',\n",
       " '되 었',\n",
       " 'ㅋㅋㅋ ㅋㅋ',\n",
       " '여운 이',\n",
       " '잘 하',\n",
       " '해야',\n",
       " '정도 로',\n",
       " '필요 없',\n",
       " '빼',\n",
       " '신선',\n",
       " '하 네',\n",
       " '가 아니',\n",
       " '그저',\n",
       " '봤 어요',\n",
       " '너무나',\n",
       " '감독 의',\n",
       " '나 도',\n",
       " '아직 도',\n",
       " '아이 들',\n",
       " '말 하',\n",
       " '나온',\n",
       " '따뜻',\n",
       " '느끼',\n",
       " '답답',\n",
       " '보 세요',\n",
       " '좋 겠',\n",
       " '이 되',\n",
       " '준다',\n",
       " '만화',\n",
       " '어야',\n",
       " '글',\n",
       " '마지막 에',\n",
       " '수작',\n",
       " '됨',\n",
       " '1 편',\n",
       " 'OOO',\n",
       " '무엇',\n",
       " '개인 적',\n",
       " '설정',\n",
       " 'ㅡ',\n",
       " '도대체',\n",
       " '되 고',\n",
       " '봤 던',\n",
       " '전쟁',\n",
       " '는 드라마',\n",
       " '마다',\n",
       " '좋 고',\n",
       " '어도',\n",
       " '것 을',\n",
       " '시절',\n",
       " '정말 재밌',\n",
       " '나 .',\n",
       " '미국',\n",
       " '감정',\n",
       " '흥미',\n",
       " '군',\n",
       " '영화 도',\n",
       " '6',\n",
       " '만든 영화',\n",
       " '드',\n",
       " '이 네요',\n",
       " '이 아니',\n",
       " '이 좋',\n",
       " '년 대',\n",
       " '형',\n",
       " '캐스팅',\n",
       " '행복',\n",
       " '허접',\n",
       " '뻔',\n",
       " '느낌 이',\n",
       " '류',\n",
       " '생각 이',\n",
       " '야 .',\n",
       " '는다 .',\n",
       " '말 고',\n",
       " '슬프',\n",
       " '앞',\n",
       " '는 장면',\n",
       " '놈',\n",
       " '엄청',\n",
       " '게 만드',\n",
       " '소름',\n",
       " '추억',\n",
       " '더라',\n",
       " '이 지만',\n",
       " '기 에',\n",
       " '으로 도',\n",
       " '오랜만 에',\n",
       " '밖에',\n",
       " '어색',\n",
       " '초반',\n",
       " '힘들',\n",
       " '사실',\n",
       " '웃음',\n",
       " '재미있 었',\n",
       " '첨',\n",
       " '질',\n",
       " '게 해',\n",
       " '관객',\n",
       " '시나리오',\n",
       " '는 좋',\n",
       " '는데 ,',\n",
       " '라니',\n",
       " '문제',\n",
       " '어 .',\n",
       " '오늘',\n",
       " '배경',\n",
       " '정신',\n",
       " '전 에',\n",
       " 'ㅋㅋㅋ ㅋㅋㅋ',\n",
       " '나 서',\n",
       " '내 인생',\n",
       " '멋진',\n",
       " '어요 !',\n",
       " '구성',\n",
       " '잡',\n",
       " '봐서',\n",
       " '졸작',\n",
       " '짜증 나',\n",
       " '. 그리고',\n",
       " '걍',\n",
       " '뻔한',\n",
       " '알 바',\n",
       " '을 하',\n",
       " '이해 가',\n",
       " '게 잘',\n",
       " '엄마',\n",
       " '위해',\n",
       " '하 는데',\n",
       " '. 보',\n",
       " '나요',\n",
       " '노 잼',\n",
       " '이 야',\n",
       " '답',\n",
       " '등',\n",
       " '분위기',\n",
       " '드라마 .',\n",
       " '가 안',\n",
       " '듯 한',\n",
       " '안 보',\n",
       " '게 없',\n",
       " '머',\n",
       " '멋있',\n",
       " '한 것',\n",
       " '뭔',\n",
       " '게 보',\n",
       " '완벽',\n",
       " '자신',\n",
       " '에 남',\n",
       " '을 듯',\n",
       " '한 거',\n",
       " '낫',\n",
       " '너무 재밌',\n",
       " '20',\n",
       " '결국',\n",
       " '었 습니다',\n",
       " '최고 다',\n",
       " '함께',\n",
       " '소리',\n",
       " '잊',\n",
       " '역사',\n",
       " '재미 가',\n",
       " '뭘',\n",
       " '어떤',\n",
       " '어이없',\n",
       " '이 .',\n",
       " '해 지',\n",
       " '가 되',\n",
       " '같 아요',\n",
       " '게 본',\n",
       " '얼마나',\n",
       " '유치 하',\n",
       " '이 정도',\n",
       " '한데',\n",
       " '우리 나라',\n",
       " '킬링',\n",
       " '포스터',\n",
       " '기억 에',\n",
       " '아무리',\n",
       " '았 던',\n",
       " '았 음',\n",
       " '애니메이션',\n",
       " '연기 는',\n",
       " '코믹',\n",
       " '간',\n",
       " '이 네',\n",
       " '됐',\n",
       " '이딴',\n",
       " '좋 아요',\n",
       " '집',\n",
       " '!!!',\n",
       " '다니 .',\n",
       " '점 은',\n",
       " '제발',\n",
       " '. 그',\n",
       " '마 라',\n",
       " '유쾌',\n",
       " '냐 .',\n",
       " '이 더',\n",
       " '이 아깝',\n",
       " '지루 한',\n",
       " '못 하',\n",
       " '있 게',\n",
       " '괜찮 은',\n",
       " '나올',\n",
       " '있 을',\n",
       " '재밌 는',\n",
       " '을 것',\n",
       " '어릴',\n",
       " '작품 이',\n",
       " '주연',\n",
       " '. 진짜',\n",
       " '더니',\n",
       " '러',\n",
       " '명작 이',\n",
       " '원',\n",
       " '후회',\n",
       " '. 이런',\n",
       " '0 점',\n",
       " '스러운',\n",
       " '으면 좋',\n",
       " '인 듯',\n",
       " 'ㅅ',\n",
       " '이건 뭐',\n",
       " '안 하',\n",
       " '잘 만들',\n",
       " '난다',\n",
       " '보 았',\n",
       " '영화 임',\n",
       " '킬링 타임',\n",
       " '~~~',\n",
       " '엇',\n",
       " '평가',\n",
       " '감동 이',\n",
       " '진부',\n",
       " '버리',\n",
       " '있 음',\n",
       " '큰',\n",
       " '알 고',\n",
       " '영화 ,',\n",
       " '은 것',\n",
       " '하 시',\n",
       " '꼭 보',\n",
       " '영화관',\n",
       " '장난',\n",
       " '둘',\n",
       " '들 .',\n",
       " '했 지만',\n",
       " '자기',\n",
       " '맘',\n",
       " '보단',\n",
       " '얼굴',\n",
       " '최고 !',\n",
       " '출연',\n",
       " '하나 도',\n",
       " '! !!!',\n",
       " '기 만',\n",
       " '영화 네요',\n",
       " '이리',\n",
       " '고 감동',\n",
       " '깊',\n",
       " '매우',\n",
       " '없 어',\n",
       " '이 왜',\n",
       " '♥',\n",
       " '만 으로',\n",
       " '영화 인',\n",
       " '옛날',\n",
       " '개연',\n",
       " '은 없',\n",
       " '갈수록',\n",
       " '꽤',\n",
       " '봐라',\n",
       " '재밌 음',\n",
       " '정말 좋',\n",
       " '충격',\n",
       " '극',\n",
       " '는 정말',\n",
       " '밖',\n",
       " '반',\n",
       " '보고',\n",
       " '예술',\n",
       " '년 전',\n",
       " '이 많',\n",
       " '라서',\n",
       " '으나',\n",
       " '을 주',\n",
       " '낭비',\n",
       " '개연 성',\n",
       " '이쁘',\n",
       " '가 좋',\n",
       " '같 은데',\n",
       " '책',\n",
       " '는 데',\n",
       " '예전',\n",
       " '이후',\n",
       " '잔인',\n",
       " '+',\n",
       " '든',\n",
       " '별점',\n",
       " '순수',\n",
       " '된다 .',\n",
       " '미친',\n",
       " '는 없',\n",
       " '배',\n",
       " '불',\n",
       " '한 스토리',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)\n",
    "TEXT.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '.', '이', '는']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'0': 0, '1': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['우리',\n",
       "  '나라',\n",
       "  '에',\n",
       "  '이런',\n",
       "  '영화',\n",
       "  '가',\n",
       "  '더',\n",
       "  '이상',\n",
       "  '나오',\n",
       "  '지',\n",
       "  '않',\n",
       "  '았',\n",
       "  '으면',\n",
       "  '.',\n",
       "  '..',\n",
       "  '이런 영화',\n",
       "  '이상 나오',\n",
       "  '았 으면',\n",
       "  '으면 .',\n",
       "  '나오 지',\n",
       "  '에 이런',\n",
       "  '더 이상',\n",
       "  '나라 에',\n",
       "  '. ..',\n",
       "  '영화 가',\n",
       "  '우리 나라',\n",
       "  '가 더',\n",
       "  '지 않',\n",
       "  '않 았'],\n",
       " 'label': '0'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data.examples[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 생성자를 만들자. 한글 데이터에선 오류가 발생해서 아래와 같이 `sort_key = lambda x: len(x.text)` 문장을 먼저 넣어줘야 오류없이 작동한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11309/874300028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/project/today_study/env/lib/python3.7/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/today_study/env/lib/python3.7/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/today_study/env/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/today_study/env/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(iter(train_iterator)).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT.vocab.itos[2533], TEXT.vocab.itos[54], TEXT.vocab.itos[2647]\n",
    "TEXT.vocab.itos[75], TEXT.vocab.itos[38], TEXT.vocab.itos[1010], TEXT.vocab.itos[1464], TEXT.vocab.itos[2934], TEXT.vocab.itos[3662]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.vocab.itos[14207], TEXT.vocab.itos[14207], TEXT.vocab.itos[556]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sent_len * batch_size] 형태로 이루어져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성\n",
    "\n",
    "여기서는 입력 문장을 임베딩 시킨 후 평균을 취한 다음 행렬곱을 취하는 모델을 사용한다. RNN을 사용하지 않기 때문에 파라미터 수가 훨씬 줄어들었다.\n",
    "\n",
    "<img src = 'https://github.com/bentrevett/pytorch-sentiment-analysis/raw/79bb86abc9e89951a5f8c4a25ca5de6a491a4f5d/assets/sentiment8.png'>\n",
    "\n",
    "평균은 다음과 같은 방식으로 취하며 `nn.functional.avg_pool2d` 를 사용한다. 이 함수는 2차원 튜플을 인수로 받으며, 입력 데이터의 마지막 2개 차원을 이용하여 평균을 산출한다.\n",
    "\n",
    "<img src = 'https://github.com/bentrevett/pytorch-sentiment-analysis/raw/79bb86abc9e89951a5f8c4a25ca5de6a491a4f5d/assets/sentiment10.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이즈 계산을 위한 함수를 사용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(name, data):\n",
    "    print(f'{name} has shape {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = torch.rand(2,5,10)\n",
    "txt.shape, F.avg_pool2d(txt, (5,1)).shape\n",
    "# (5 x 1) 크기의 필터를 옮겨가며 평균을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = torch.tensor(\n",
    "    [[[1,2,3,4],[4,5,6,7]]], dtype=torch.float\n",
    ")\n",
    "print(txt.shape,\"\\n\", txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.avg_pool2d(txt, (2,1)).shape, F.avg_pool2d(txt, (2,1))\n",
    "# (2 x 1) 필터로 평균을 취함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.avg_pool2d(txt, (2,2)).shape, F.avg_pool2d(txt, (2,2))\n",
    "# (2 x 2) 필터로 평균을 취함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FastText` 모델을 구현하자. 다만 여기서 주의할 점!\n",
    "\n",
    "* RNN은 [sent_len, batch_size, embedding_dim] 크기의 텐서를 입력으로 받음\n",
    "* CNN은 [batch_size, sent_len, embedding_dim] 크기의 텐서를 입력으로 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastText(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text = [sent_len, batch_size]\n",
    "        #print_shape('text', text)\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        #print_shape('embedded', embedded)\n",
    "        # embedded = [sent_len, batch_size, embedding_dim]\n",
    "        \n",
    "        # CNN은 [batch_size, sent_len, embedding_dim] 를 입력으로 받음\n",
    "        # 따라서 permute 취해줘야 함\n",
    "        embedded = embedded.permute(1,0,2)\n",
    "        #print_shape('embedded', embedded)\n",
    "        # embedded = [batch_size, sent_len, embedding_dim]\n",
    "        \n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1],1)).squeeze(1)\n",
    "        #print_shape('pooled', pooled)\n",
    "        # pooled = [batch_size, embedding_dim]\n",
    "        \n",
    "        res = self.fc(pooled)\n",
    "        #print_shape('res', res)\n",
    "        # res = [batch_size, output_dim]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이즈 계산 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp = next(iter(train_iterator))\n",
    "#model(inp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 하이퍼파라미터를 설정하고 인스턴스화 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "OUTPUT_DIM = 1\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 파라미터 갯수는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'모델의 파라미터 수는 {count_parameters(model):,} 개 입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난 모델에 비해 약 3/4 으로 감소했다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 훈련된 단어 벡터를 덮어 쓰자. 먼저 텐서 차원을 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_weight = TEXT.vocab.vectors\n",
    "# print(pretrained_weight.shape, model.embedding.weight.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.embedding.weight.data.copy_(pretrained_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`UNK_IDX`와 `PAD_IDX`는 제로 처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "\n",
    "이전과 동일하게 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds==y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 함수를 정의하자. 여기선 드랍아웃 안쓰지만 걍 `model.train()` 사용하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(1) # output_dim = 1\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얼마나 훈련 걸리는 지 체크하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 훈련시켜보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이럴수가. 사전 훈련된 벡터 안써도 큰 차이가 없음....\n",
    "\n",
    "테스트셋에서 돌려보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut3-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더 훈련시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+6:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오버피팅이 발생하고 있다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut3-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능은 이전 모델과 거의 비슷하지만 훈련 시간이 대폭 감소!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자 데이터 사용\n",
    "\n",
    "영화 평가 데이터 직접 넣어보자.\n",
    "\n",
    "다음 기능을 하는 `predict_sentiment` 함수를 만들자.\n",
    "\n",
    "* sets the model to evaluation mode\n",
    "* tokenizes the sentence, i.e. splits it from a raw string into a list of tokens\n",
    "* indexes the tokens by converting them into their integer representation from our vocabulary\n",
    "* gets the length of our sequence\n",
    "* converts the indexes, which are a Python list into a PyTorch tensor\n",
    "* add a batch dimension by unsqueezeing\n",
    "* converts the length into a tensor\n",
    "* squashes the output prediction from a real number between 0 and 1 with the `sigmoid` function\n",
    "* converts the tensor holding a single value into an integer with the item() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = generate_bigrams([tok for tok in mecab.morphs(sentence)])\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1) # 배치 \n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"이 영화 진짜 재밌었다!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"영화관에서 이걸 본 내가 바보다. 내 돈 돌려줘!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"이 영화 감독 밥은 먹고 다니냐? 이런 영화 만들고 잠이 와?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"내 인생 영화 등극. 주인공한테 너무 몰입해서 시간 가는 줄도 몰랐다...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"초반부는 재미는 있엇는데, 근데 후반부가... 질질끌엇음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "02f73df80f6b7cfb1d2d2729c6624b9061c0386599073f9b468acf97e0bc0e85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
