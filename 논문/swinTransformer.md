
swin transformer

VIT 포지션 임베딩
-> 학습이 가능하도록 변수로 지정

기존존 vit는 분류 문제를 풀기위한 모델로 제안
이미지 토큰수가 증가함에 따라 연산량이 quadratic하게 증가함에


제안내용 
다양한 목적에 백본으로 사용될 수 있는 모델 제안
트랜스포머 구조에 이미지의 특성을 반영할 수 있는 방법 제안량
기존 VIT보다 적은 연산량



![](../%EC%9D%B4%EB%AF%B8%EC%A7%80/%EB%85%BC%EB%AC%B8/swin_tr/Screenshot%20from%202022-08-08%2014-10-54.png)



----------------
M : 윈도우 사이즈 - 윈도우 사이즈는 패치 갯수로 정함
n : 한 윈도우의 패치 갯수
N : 전체 패치갯수

![](../%EC%9D%B4%EB%AF%B8%EC%A7%80/%EB%85%BC%EB%AC%B8/swin_tr/Screenshot%20from%202022-08-08%2014-12-38.png)


--------------------------
swin tr은 
해상도, 물체크기 등 이미지 특성을 고려햇다라고 볼수 있음

local window를 모델에 적용
각 윈도우 안에서 어텐션을 적용한다, 계층마다 다른 해상도에 대해 어텐션을 적용하므로,
디텍션,세그멘테이션에 적합하다

https://www.youtube.com/watch?v=2lZvuU_IIMA
* 12분부터 볼것!


vit와 다른점은 cls토큰을 쓰지 않음
각 토큰들의 평균값을 사용하여 분류문제를 해결함

로컬 윈도우를 적용해 기존 vit보다 더 적은 복잡성을 가짐 
local window를 적용하여 인덕티브바이어스를 개입
패치 머징을 통해 계층적 구조 형성








