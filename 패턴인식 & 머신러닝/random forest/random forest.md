https://www.youtube.com/watch?v=lIT5-piVtRw

---------------------
랜덤포레스트 배경 - (앙상블)
여러 모델들의 예측을 다수결 법칙 또는 평균을 이용해 통합하여 예측 정확성을 향상시키는 방법



다음 조건을 만족할때 앙상블 모델은 단일 모델보다 우수한 성능을 보여줌
- 앙상블 모델들이 서로 독립적
- 모델들이 무작위 예측을 수행하는 모델보다 성능이 좋은 경우 - ??
-> 어중간하게 이진 분류기 일경우, 0.5 이런 값들이 나오지 않아야 함, 앙상블 모델이 안좋은 경우 단일모델 모다 성능이 떨어질수 있음



----------------------------------------------
랜덤포레스트
-> 앙상블 (base 모델을)을 의사결정 나무모델의 집합으로 한것

특징
-> 데이터의 크기가 방대한 경우에도 모델을 빨리 구축가능
-> 데이터 분포에 대한 전제가 필요하지 않음

모델 학습 플로우
1. bootstrap 기법을 이용하여 다수의 training 데이터 생성
2. 생성된 트레이닝 데이터로 dicision tree 모델 구축 (무작위 변수를 사용하여)
3. 예측 종합

--------------------------------
랜덤포레스트 핵심아이디어
diversity, random 확보

bootstrap 기법을 이용하여 다수의 training 데이터 생성, 각데이터 마다 개별 의사결정 나무모델을 구축
-> bagging 기법

의사결정나무모델 구축시 변수 무작위로 선택 
-> random subspace

-------------------------------
bagging이란? - bootstrap aggregating의 줄임말 
-> bootstrap으로 구성된 결과를 aggregating(합친다)라고 해석

bootstrap이란?
-> 데이터 샘플링 기법

- 각 모델은 서로 다른 데이터셋을 이용
- 각 데이터셋은 복원추출(sampleing with replacement)를 통해 원래 데이터의 수만큼의 크기를 갖도록 샘플링
-> 데이터를 뽑고 다시 넣음, 중복 데이터가 나옴
- 개별 데이터 셋을 부트 스트랩셋이라고 부름 

이론적으로 부트스트랩 데이터셋에서, 한개체가 하나의 부트스트랩 셋에 한번도 선택되지 않을 확률은? 0.36~7%

10분 그림 꼭 참조할것!

합칠때 아이디어
1. 다수결
2. 트레이닝 정확도를 가중치로 쓴다
3. 단순 평균
-------------------------------------------------------------

random subspace
원래변수들 중에서 모델 구축에 쓰일 입력변수를 무작위로 선택

random subspace가 필요한 이유는?
-> 모델의 랜덤성을 확보하기 위해








































